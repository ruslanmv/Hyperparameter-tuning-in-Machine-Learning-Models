{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7a5211",
   "metadata": {},
   "source": [
    "# How to use the parameters in Neural-Networks\n",
    "\n",
    "\n",
    "Today I will discuss about how to adjust the parameters of the neural networks from unknonwn Neural Networks.\n",
    "\n",
    "\n",
    "\n",
    "In ordering to select the appropiate parameters in a simple Neural Network for example in case of a Convolutional  Neural Network , we should remember the meaning of all the layers and understand the \n",
    "the following parameters:\n",
    "\n",
    "- Activation Shape\n",
    "- Activation Size \n",
    "- Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76edfc4",
   "metadata": {},
   "source": [
    "# Analysis of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f59fb6",
   "metadata": {},
   "source": [
    "To build the neural network, we should know the dimensions of the layers that are include in the network.\n",
    "\n",
    "In this work we will use three types of layers in a convolution\n",
    "- Convolution (CONV)\n",
    "- Pooling  (POOL) \n",
    "- Fully connected (FC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df4bda",
   "metadata": {},
   "source": [
    "### Parameters in Convolution Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc34b38",
   "metadata": {},
   "source": [
    "To understand better the layers we have to understand the parameters involved in the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8656100",
   "metadata": {},
   "source": [
    "Let us define several helper functions that allow us understand how the Neural Networks works and use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a26496a",
   "metadata": {},
   "source": [
    "## Convolution (CONV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2cf0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_valid_convolution(inputs,  kernel):\n",
    "    '''\n",
    "    input\n",
    "    nh : height\n",
    "    nw : widht\n",
    "    \n",
    "    kernel\n",
    "    fh : filter\n",
    "    fw : filter\n",
    "    '''\n",
    "    nh,nw,= inputs\n",
    "    fh,fw = kernel\n",
    "    return (nh-fh) + 1, (nw-fw) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e2f00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = 6 , 6  # nxn image\n",
    "filters = 3 , 3 # fxf filter\n",
    "dim_valid_convolution( inputs, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1776b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_same_convolution(inputs,  kernel,s,p):\n",
    "    '''\n",
    "    Output size is the same as input size\n",
    "    \n",
    "    input\n",
    "    nh : height\n",
    "    nw : widht\n",
    "    \n",
    "    kernel\n",
    "    fh : filter\n",
    "    fw : filter\n",
    "    '''\n",
    "    nh,nw,= inputs\n",
    "    fh,fw = kernel\n",
    "    return (nh+2*p-fh) + 1, (nw+2*p-fw) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a76cae",
   "metadata": {},
   "source": [
    "We choose pad in a way that the output size is the same as the input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f72c1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 6 , 6  # nxn image\n",
    "filters = 3 , 3 # fxf filter\n",
    "stride=1.0    #stride s\n",
    "padding=1.0   # padding s\n",
    "parameters=dim_same_convolution( inputs, filters,stride,padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "124fc227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_same(inputs,parameters):\n",
    "    #2D\n",
    "    if len(parameters)==2 :\n",
    "        assert parameters[0] == inputs[0] and  parameters[1] ==inputs[1],\"It is not same convolution, please fix the stride or padding for the input\"+str(inputs)+\"and parameters \"+str(parameters)      \n",
    "    #3D    \n",
    "    if len(parameters)==3 :\n",
    "        assert parameters[0][0] == inputs[0] and  parameters[0][1] ==inputs[1],\"It is not same convolution, please fix the stride or padding for the input\"+str(inputs)+\"and parameters \"+str(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e24796c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_same(inputs,parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a319d2a",
   "metadata": {},
   "source": [
    "![strided](img/strided.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c569553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dim_strided_convolution(inputs, kernel ,s,p):\n",
    "    '''\n",
    "    input = (nh, nw)\n",
    "    nh : height\n",
    "    nw : widht\n",
    "    \n",
    "    kernel = (fh, fw)\n",
    "    fh : filter height\n",
    "    fw : filter widht\n",
    "\n",
    "    p : padding\n",
    "    s : stride\n",
    "\n",
    "    '''\n",
    "    nh,nw= inputs\n",
    "    fh,fw= kernel\n",
    "    \n",
    "    \n",
    "    print(\"Activation Shape Strided\")\n",
    "\n",
    "    \n",
    "    return (nh+2*p-fh)/s + 1, (nw+2*p-fw)/s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d741a913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape Strided\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.0, 3.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = 7,7  # nxn image\n",
    "kernel = 3,3  # fxf filter\n",
    "stride=2.0    #stride s\n",
    "padding=0.0   # padding s\n",
    "dim_strided_convolution(inputs, kernel ,stride,padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6437462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_rgb_convolution(inputs, kernel,stride,padding,filters):\n",
    "    '''\n",
    "    input = (nh, nw, nc)\n",
    "    where \n",
    "    nh: height\n",
    "    nw: widht\n",
    "    nc: channels\n",
    "    \n",
    "    output = (nhl,nwl,ncl)\n",
    "       \n",
    "    nhl = (nh+2*p-fw)/s + 1\n",
    "    nwl = (nw+2*p-fh)/s + 1\n",
    "    ncl = filters\n",
    "    \n",
    "    \n",
    "    where\n",
    "       fw,fh : filter sizes\n",
    "       p : padding\n",
    "       s : stride  \n",
    "    ncl  : filters\n",
    "    \n",
    "    '''\n",
    "    nh,nw,nc = inputs\n",
    "    fh,fw = kernel\n",
    "     \n",
    "    s        = stride\n",
    "    p        = padding\n",
    "    ncl      = filters\n",
    "\n",
    "    nhl = (nh+2*p-fw)/s + 1\n",
    "    nwl = (nw+2*p-fh)/s + 1\n",
    "    output = (int(nhl),int(nwl),int(ncl))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Activation Shape\")\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55798a78",
   "metadata": {},
   "source": [
    "Let us define the number of parameters used in each convolution,\n",
    "The paremeters are defined as  ((shape of width of filter x shape of height filter x number of filters in the previous layer+1) x number of filters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d90c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nparameters_convolution(inputs, kernel,stride,padding,filters):\n",
    "    '''\n",
    "    input = (nh, nw, nc)\n",
    "    where \n",
    "    nh: height\n",
    "    nw: widht\n",
    "    nc: channels\n",
    "    \n",
    "    activation_shape  = (nhl,nwl,ncl)\n",
    "       \n",
    "    nhl = (nh+2*p-fw)/s + 1\n",
    "    nwl = (nw+2*p-fh)/s + 1\n",
    "    ncl = filters\n",
    "    \n",
    "    \n",
    "    where\n",
    "       fw,fh : filter sizes\n",
    "       p : padding\n",
    "       s : stride  \n",
    "    ncl  : filters\n",
    "    \n",
    "    '''\n",
    "    nh,nw,nc = inputs\n",
    "    fh,fw = kernel\n",
    "     \n",
    "    s        = stride\n",
    "    p        = padding\n",
    "    ncl      = filters\n",
    "    \n",
    "    #activation shape \n",
    "    nhl = (nh+2*p-fw)/s + 1\n",
    "    nwl = (nw+2*p-fh)/s + 1\n",
    "    activation_shape = (int(nhl),int(nwl),int(ncl))\n",
    "    \n",
    "    # activation size\n",
    "    activation_size=int(nhl)*int(nwl)*int(ncl)\n",
    "    \n",
    "    \n",
    "    # number Parameters\n",
    "    nparameters=((fh*fw*nc)+1)*ncl\n",
    "    \n",
    "    print(\"Activation Shape,\", \"Activation Size,\",\"# Parameters\")\n",
    "     \n",
    "    return   activation_shape ,  activation_size, nparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d389fc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((28, 28, 8), 6272, 608)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  = 32,32,3  #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 8       #number of filters ncl\n",
    "\n",
    "\n",
    "\n",
    "nparameters_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934cd63",
   "metadata": {},
   "source": [
    "![convnet](img/convnet.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16e61108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37, 37, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  = 39,39,3  #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 10       #number of filters ncl\n",
    "\n",
    "dim_rgb_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a6b55",
   "metadata": {},
   "source": [
    "Where  the activation size, considering it’s merely the product of width, height and the number of channels in that layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d323d7cb",
   "metadata": {},
   "source": [
    "The input layer’s shape is (37, 37, 10), the activation size of that layer is 37* 37* 10 = 13690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9fea408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13690"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37* 37* 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dc8cede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17, 17, 20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  = 37,37,10  #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 20       #number of filters ncl\n",
    "\n",
    "\n",
    "dim_rgb_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb88d8",
   "metadata": {},
   "source": [
    "The sme happens if we want to calculate the activation size for this convolution. All we have to do is just multiply (17, 17, 20) , i.e 17* 17* 20= 5780 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c86653be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5780"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17* 17* 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c1f5010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 7, 40)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  = 17,17,20  #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 40       #number of filters ncl\n",
    "\n",
    "dim_rgb_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3ddea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7, 7, 40), 1960, 20040)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparameters_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6491364",
   "metadata": {},
   "source": [
    "The number of parameters in a given layer is the count of “learnable”  elements for a filter aka parameters for the filter for that layer. Parameters in general are weights that are learnt during training. They are weight matrices that contribute to model’s predictive power, changed during back-propagation process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70554f80",
   "metadata": {},
   "source": [
    "## Pooling (POOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5916a",
   "metadata": {},
   "source": [
    "In the pooling there are the following Hyperparameters:\n",
    "\n",
    "- f: filter size\n",
    "\n",
    "- s: stride\n",
    "- Max or average pooling\n",
    "\n",
    "Given an input with the dimensions\n",
    "\n",
    "$$n_H \\times n_W \\times n_C$$\n",
    "\n",
    "Max or  pooling is has the following dimensions\n",
    "\n",
    "$$ \\frac{n_H+2p-f}{s}+1 \\times \\frac{n_W+2p-f}{s}+1 \\times n_C$$ \n",
    "\n",
    "The numbers of channels remains $$n_C$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b11e2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_pool(inputs, kernel,stride,padding):\n",
    "    '''\n",
    "    input = (nh, nw, nc)\n",
    "    where \n",
    "    nh: height\n",
    "    nw: widht\n",
    "    nc: channels\n",
    "    \n",
    "    activation_shape  = (nhl,nwl,ncl)\n",
    "       \n",
    "    nhl = (nh+2*p-fw)/s + 1\n",
    "    nwl = (nw+2*p-fh)/s + 1\n",
    "    ncl = nc\n",
    "    where\n",
    "       fw,fh : filter sizes\n",
    "       p : padding\n",
    "       s : stride     \n",
    "    '''\n",
    "    nh,nw,nc = inputs\n",
    "    fh,fw = kernel\n",
    "     \n",
    "    s        = stride\n",
    "    p        = padding\n",
    "    ncl      = nc\n",
    "\n",
    "    nhl = (nh+2*p-fw)/s + 1\n",
    "    nwl = (nw+2*p-fh)/s + 1\n",
    "    activation_shape = (int(nhl),int(nwl),int(ncl))\n",
    "\n",
    "\n",
    "    # activation size\n",
    "    activation_size=int(nhl)*int(nwl)*int(ncl)\n",
    "    \n",
    "    \n",
    "    # number Parameters\n",
    "    nparameters=0\n",
    "    \n",
    "    print(\"Activation Shape,\", \"Activation Size,\",\"# Parameters\")\n",
    "     \n",
    "    return   activation_shape ,  activation_size, nparameters    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9583d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3, 3, 5), 45, 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  = 5,5,5 #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "\n",
    "dim_pool(inputs, kernel,stride,padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "724356c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3, 3, 1000), 9000, 0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  = 7,7,1000 #nw x nh x nc image\n",
    "kernel  = 2,2      #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "\n",
    "\n",
    "dim_pool(inputs, kernel,stride,padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc7dc8c",
   "metadata": {},
   "source": [
    "![convnet](img/lenet5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b75b4",
   "metadata": {},
   "source": [
    "The input layer’s shape is (32, 32, 3), the activation size of that layer is 32 * 32 * 3 = 3072."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b6b8b",
   "metadata": {},
   "source": [
    "### CONV 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33550862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 28, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  =32,32,3  #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 8 #6       #number of filters ncl\n",
    "\n",
    "newinput=dim_rgb_convolution(inputs, kernel,stride,padding,filters)\n",
    "newinput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad4f550",
   "metadata": {},
   "source": [
    "The activation size for CONV1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee432f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6272"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28* 28* 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7285635",
   "metadata": {},
   "source": [
    "Parameters  CONV1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc7640",
   "metadata": {},
   "source": [
    "```\n",
    "((fw x fw *nc +1)*ncl)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1de97c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((5*5*3)+1)*8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4dc3fe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((28, 28, 8), 6272, 608)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  =32,32,3  #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 8       #number of filters ncl\n",
    "\n",
    "nparameters_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba01989f",
   "metadata": {},
   "source": [
    "### POOL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3c203e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((14, 14, 8), 1568, 0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  = 28, 28, 8 #nw x nh x nc \n",
    "kernel  = 2,2     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "\n",
    "dim_pool(inputs, kernel,stride,padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022b7113",
   "metadata": {},
   "source": [
    "The activation size for POOL1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8207508f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14* 14* 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f1620",
   "metadata": {},
   "source": [
    "### CONV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c39e106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 10, 16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  =14, 14, 8 #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 16       #number of filters ncl\n",
    "\n",
    "newinput=dim_rgb_convolution(inputs, kernel,stride,padding,filters)\n",
    "newinput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c4c34",
   "metadata": {},
   "source": [
    "The activation size for CONV2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "321a2c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10*10*16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1af0720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10, 10, 16), 1600, 3216)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  =14, 14, 8 #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 16       #number of filters ncl\n",
    "\n",
    "\n",
    "nparameters_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3274b8",
   "metadata": {},
   "source": [
    "### POOL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd6ddc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5, 5, 16), 400, 0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs  = 10, 10, 16 #nw x nh x nc \n",
    "kernel  = 2,2     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "\n",
    "dim_pool(inputs, kernel,stride,padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566cc0f9",
   "metadata": {},
   "source": [
    "The activation size for POOL2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edc8a785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5* 5* 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce53d2ff",
   "metadata": {},
   "source": [
    "Parameters in general are weights that are learnt during training. They are weight matrices that contribute to model’s predictive power, changed during back-propagation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4bf56",
   "metadata": {},
   "source": [
    "###  FULLY CONNECTED LAYER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b7d58",
   "metadata": {},
   "source": [
    "To calculate the learnable parameters here, all we have to do is just multiply the by the shape of width hw, height hw, previous layer's filters nc and account for all such filters k in the current layer. Don't forget the bias term for each of the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "937934ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nparameters_fully_connected(c , p):\n",
    "    '''\n",
    "    current layer dimension: c\n",
    "    previous layer activation size: p  \n",
    "    '''\n",
    "    \n",
    "    #activation shape \n",
    "    activation_shape = (c,1)\n",
    "    \n",
    "    # activation size\n",
    "    activation_size=c\n",
    "    \n",
    "    \n",
    "    number=(( c *  p)+1 * c) \n",
    "    print(\"Activation Shape,\", \"Activation Size,\",\"# Parameters\")\n",
    "\n",
    "    return activation_shape, activation_size, number    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09d92b",
   "metadata": {},
   "source": [
    "## FC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "337c0716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((120, 1), 120, 48120)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparameters_fully_connected(120 , 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab220388",
   "metadata": {},
   "source": [
    "## FC4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61740b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((84, 1), 84, 10164)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparameters_fully_connected(84 , 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ebcb7",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6ade34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10, 1), 10, 850)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparameters_fully_connected(10 , 84)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a76f0eb",
   "metadata": {},
   "source": [
    "Up to now we have seen the dimensions of the activation shape, the activation size and the number of parameters. Let us put in practice this knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def0002",
   "metadata": {},
   "source": [
    "# How to use  AlexNet Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52331199",
   "metadata": {},
   "source": [
    "\n",
    "For this project I will take two differnet models of  AlexNet applied to an unknown dataset from the problem given at the [MMORPG-AI](https://github.com/ruslanmv/BOT-MMORPG-AI)\n",
    "\n",
    "The models to analize are:\n",
    "\n",
    "- Non adapted model\n",
    "- Adapted model\n",
    "\n",
    "The **non adapted model** is just take the \"raw\" definition of the AlexNet Network from the standard python code here\n",
    "\n",
    "\n",
    "The **adapted model** is the version where we modify the parameters of the non adapted model in according to the Analysis previous done in this blog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46936982",
   "metadata": {},
   "source": [
    "Let us first load the libraries that we need to begin the discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6fcd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Gamepad library\n",
    "from mmorpg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b9dfa",
   "metadata": {},
   "source": [
    "The important part is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4d02d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the size of the pictures\n",
    "WIDTH = 480\n",
    "HEIGHT = 270"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7769c1c",
   "metadata": {},
   "source": [
    "We load the data of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b71a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load the images of the gameplay\n",
    "x_training_data=pd.read_pickle('data/dfx-0.pkl')  \n",
    "#We load the inputs of the of the gameplay\n",
    "y_training_data=pd.read_pickle('data/dfy-0.pkl')  \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x_training_data, y_training_data, test_size=0.2, random_state=6)\n",
    "# Train Image part ( 4 Dimensional)\n",
    "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
    "X=X_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "#Train Input part ( 1 Dimensional )\n",
    "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
    "# Test Image part ( 4 Dimensional)\n",
    "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
    "test_x=test_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "## Test Input part( 1 Dimensional )\n",
    "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68faf81",
   "metadata": {},
   "source": [
    "# Alexnet Model - Non adapted model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725eb99e",
   "metadata": {},
   "source": [
    "We define the standard AlexNet non adapted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe3526dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "MODEL_NAME = 'mmorpg-{}-{}.model'.format(LR, 'alexnet-non-adapted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b18a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet(width, height, lr, output=29):\n",
    "    # Building 'AlexNet'                                                  #line\n",
    "    network = input_data(shape=[None, width, height, 3])                  #0\n",
    "    network = conv_2d(network, 96, 11, strides=4, activation='relu')      #1\n",
    "    network = max_pool_2d(network, 3, strides=2)                          #2\n",
    "    network = local_response_normalization(network)                       #3\n",
    "    network = conv_2d(network, 256, 5, activation='relu')                 #4\n",
    "    network = max_pool_2d(network, 3, strides=2)                          #5\n",
    "    network = local_response_normalization(network)                       #6\n",
    "    network = conv_2d(network, 384, 3, activation='relu')                 #7\n",
    "    network = conv_2d(network, 384, 3, activation='relu')                 #8\n",
    "    network = conv_2d(network, 256, 3, activation='relu')                 #9\n",
    "    network = max_pool_2d(network, 3, strides=2)                          #10\n",
    "    network = local_response_normalization(network)                       #11\n",
    "    network = fully_connected(network, 4096, activation='tanh')           #12\n",
    "    network = dropout(network, 0.5)                                       #13\n",
    "    network = fully_connected(network, 4096, activation='tanh')           #14\n",
    "    network = dropout(network, 0.5)                                       #15\n",
    "    network = fully_connected(network, 29, activation='softmax')          #16\n",
    "    network = regression(network, optimizer='momentum',                   #17\n",
    "                         loss='categorical_crossentropy',\n",
    "                         learning_rate=0.001)\n",
    "\n",
    "    # Training\n",
    "    model = tflearn.DNN(network, checkpoint_path='model_alexnet',\n",
    "                        max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir='log')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "470a8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet(WIDTH, HEIGHT, LR, output=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf31308",
   "metadata": {},
   "source": [
    "We train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50de177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m1.97406\u001b[0m\u001b[0m | time: 21.022s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 005 | loss: 1.97406 - acc: 0.4897 -- iter: 180/180\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=5, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=64, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb5fd7",
   "metadata": {},
   "source": [
    "We have seen that the accuracy is less than **0.5** and the loss near to **2.0** . With the knowledge of the dimensions studied before we will adapt the model in appropiate way **to improve** the AlexNet model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c53b1",
   "metadata": {},
   "source": [
    "### Understanding the parameters of AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c753b2ed",
   "metadata": {},
   "source": [
    "The standard AlexNet network may be depicted as the Cousera Deep Learning Course:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f21199",
   "metadata": {},
   "source": [
    "![AlexNet](img/alex.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e166c7d8",
   "metadata": {},
   "source": [
    "Where we obtain the essential parameters for each of the layers depicted in the previous picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a74cb1",
   "metadata": {},
   "source": [
    "The inputs of the neural nework in tensorflow is given by\n",
    "```\n",
    "input_data(shape=[None, width, height, 3])                  #0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "65b6074f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((55, 55, 96), 290400, 34944)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONV 1\n",
    "inputs  =227,227,3  #nw x nh x nc image\n",
    "kernel  = 11,11      #fw x fw  filter\n",
    "stride  = 4.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 96       #number of filters ncl\n",
    "nparameters_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433cf7f",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to \n",
    "```\n",
    "conv_2d(network, 96, 11, strides=4, activation='relu')      #1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "fbad6207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((27, 27, 96), 69984, 0)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#POOL1\n",
    "inputs  = 55, 55, 96 #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "dim_pool(inputs, kernel,stride,padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d27b7ce",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to \n",
    "```\n",
    "max_pool_2d(network, 3, strides=2)                          #2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73451236",
   "metadata": {},
   "source": [
    "After using a pool we can use a normalization\n",
    "```\n",
    "local_response_normalization(network)                       #3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "9b1e3d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((27, 27, 256), 186624, 614656)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONVOLUTION SAME 1\n",
    "inputs  =27, 27, 96 #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 2.0      #padding p\n",
    "filters = 256       #number of filters ncl\n",
    "nparameters_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a2970",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to:\n",
    "```\n",
    "conv_2d(network, 256, 5, activation='relu')                 #4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "25dfef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13, 13, 256), 43264, 0)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#POOL2\n",
    "inputs  = 27, 27, 256 #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "dim_pool(inputs, kernel,stride,padding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722b036",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to:\n",
    "```\n",
    "max_pool_2d(network, 3, strides=2)                          #5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34fec7",
   "metadata": {},
   "source": [
    "After a pool in we use:\n",
    "\n",
    "```\n",
    "local_response_normalization(network)                       #6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b2a48653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13, 13, 384), 64896, 885120)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONVOLUTION SAME 2\n",
    "inputs  =13, 13, 256 #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = 384       #number of filters ncl\n",
    "nparameters_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c19eba",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to:\n",
    "```\n",
    "conv_2d(network, 384, 3, activation='relu')                 #7\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "9af995cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13, 13, 384), 64896, 1327488)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONVOLUTION SAME 3\n",
    "inputs  =13, 13, 384 #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = 384       #number of filters ncl\n",
    "nparameters_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba2a60",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to:\n",
    "```\n",
    "conv_2d(network, 384, 3, activation='relu')                 #8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5cac80cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13, 13, 256), 43264, 884992)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONVOLUTION SAME 4\n",
    "inputs  =13, 13, 384 #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = 256       #number of filters ncl\n",
    "nparameters_convolution(inputs, kernel,stride,padding,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376835a",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to:\n",
    "```\n",
    "conv_2d(network, 256, 3, activation='relu')                 #9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "fcc35704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((6, 6, 256), 9216, 0)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#POOL3\n",
    "inputs  = 13, 13, 256 #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "dim_pool(inputs, kernel,stride,padding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6770cc3",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to:\n",
    "```\n",
    "max_pool_2d(network, 3, strides=2)                          #10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ab075",
   "metadata": {},
   "source": [
    "After pool we use a normalization\n",
    "```\n",
    "local_response_normalization(network)                       #11\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "90b235a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4096, 1), 4096, 37752832)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FC1\n",
    "nparameters_fully_connected(4096 , 9216)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39d7626",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to:\n",
    "```\n",
    "fully_connected(network, 4096, activation='tanh')           #12\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b9f03",
   "metadata": {},
   "source": [
    "Dropout can be used after convolutional layers (e.g. Conv2D) and after pooling layers (e.g. MaxPooling2D). Often, dropout is only used after the pooling layers, but this is just a rough heuristic. After fully connected layer we use  dropout to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e622a94",
   "metadata": {},
   "source": [
    "```\n",
    "dropout(network, 0.5)                                       #13\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "bc995201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4096, 1), 4096, 16781312)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FC2\n",
    "nparameters_fully_connected(4096 , 4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa548ff9",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to:\n",
    "```\n",
    "fully_connected(network, 4096, activation='tanh')           #14\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5d9a2",
   "metadata": {},
   "source": [
    "After fully connected layer we use dropout \n",
    "```\n",
    "dropout(network, 0.5)                                       #15\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7042807c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1000, 1), 1000, 4097000)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Softmax\n",
    "nparameters_fully_connected(1000 , 4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e6a8b5",
   "metadata": {},
   "source": [
    "In TensorFlow this part corresponds to:\n",
    "```\n",
    "fully_connected(network, 29, activation='softmax')          #16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb458ea",
   "metadata": {},
   "source": [
    "## Full code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052e917",
   "metadata": {},
   "source": [
    "Let us write the parameters Alexnet network in asimple code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "9eaa8c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    }
   ],
   "source": [
    "parameters={}\n",
    "\n",
    "#Input layer\n",
    "parameters[0]=227,227,3\n",
    "\n",
    "#CONV 1\n",
    "inputs  =parameters[0]  #nw x nh x nc image\n",
    "kernel  = 11,11      #fw x fw  filter\n",
    "stride  = 4.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 96       #number of filters ncl\n",
    "parameters[1]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "#POOL1\n",
    "inputs  = parameters[1][0] #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "parameters[2]=dim_pool(inputs, kernel,stride,padding)\n",
    "#CONVOLUTION SAME 1\n",
    "inputs  =parameters[2][0] #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 2.0      #padding p\n",
    "filters = 256       #number of filters ncl\n",
    "parameters[3]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[3]) # Checking parameters of same convolution\n",
    "\n",
    "#POOL2\n",
    "inputs  = parameters[3][0] #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "parameters[4]=dim_pool(inputs, kernel,stride,padding)\n",
    "\n",
    "#CONVOLUTION SAME 2\n",
    "inputs  =parameters[4][0] #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = 384       #number of filters ncl\n",
    "parameters[5]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[5]) # Checking parameters of same convolution\n",
    "\n",
    "\n",
    "#CONVOLUTION SAME 3\n",
    "inputs  =parameters[5][0] #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = 384       #number of filters ncl\n",
    "parameters[6]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[6]) # Checking parameters of same convolution\n",
    "\n",
    "\n",
    "#CONVOLUTION SAME 4\n",
    "inputs  =parameters[6][0] #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = 256       #number of filters ncl\n",
    "parameters[7]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[7]) # Checking parameters of same convolution\n",
    "\n",
    "#POOL3\n",
    "inputs  = parameters[7][0] #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "parameters[8]=dim_pool(inputs, kernel,stride,padding)\n",
    "#FC1\n",
    "parameters[9]=nparameters_fully_connected(4096 , parameters[8][1])\n",
    "#FC2\n",
    "parameters[10]=nparameters_fully_connected(parameters[9][1] , parameters[9][1])\n",
    "#Softmax\n",
    "parameters[11]=nparameters_fully_connected(1000 , parameters[10][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21890665",
   "metadata": {},
   "source": [
    "From the previous analysis we can parametrize the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec16adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet_parametrized(width, height, lr, output=29):\n",
    "    # Building 'AlexNet'                                                               #line\n",
    "    network = input_data(shape=[None, width, height, 3])                               #0\n",
    "    network = conv_2d(network, filters1, kernel1, stride1, activation='relu')          #1\n",
    "    network = max_pool_2d(network, kernel2, strides=stride2 )                          #2\n",
    "    network = local_response_normalization(network)                                    #3\n",
    "    network = conv_2d(network, filters3 , kernel3 , activation='relu')                 #4\n",
    "    network = max_pool_2d(network, kernel4, strides=stride4)                           #5\n",
    "    network = local_response_normalization(network)                                    #6\n",
    "    network = conv_2d(network, filters5 , kernel5 , activation='relu')                 #7\n",
    "    network = conv_2d(network, filters6 , kernel6 , activation='relu')                 #8\n",
    "    network = conv_2d(network, filters7, kernel7 , activation='relu')                  #9\n",
    "    network = max_pool_2d(network, kernel8 , strides=stride8 )                         #10\n",
    "    network = local_response_normalization(network)                                    #11\n",
    "    network = fully_connected(network, activation9, activation='tanh')                 #12\n",
    "    network = dropout(network, dropout13)                                              #13\n",
    "    network = fully_connected(network, activation10, activation='tanh')                #14\n",
    "    network = dropout(network, dropout15)                                              #15\n",
    "    network = fully_connected(network, outputs11, activation='softmax')                #16\n",
    "    network = regression(network, optimizer='momentum',                                #17\n",
    "                         loss='categorical_crossentropy',\n",
    "                         learning_rate=learning_rate17)\n",
    "\n",
    "    # Training\n",
    "    model = tflearn.DNN(network, checkpoint_path='model_alexnet',\n",
    "                        max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir='log')\n",
    "\n",
    "    return model\n",
    "\n",
    "#Paramters          Operation \n",
    "filters1     =  96     #1\n",
    "kernel1      =  11       \n",
    "stride1      =  4\n",
    "kernel2      =  3      #2\n",
    "stride2      =  2\n",
    "filters3     =  256    #3\n",
    "kernel3      =  5\n",
    "kernel4      =  3      #4\n",
    "stride4      =  2\n",
    "filters5     =  384    #5\n",
    "kernel5      =  3\n",
    "filters6     =  384    #6\n",
    "kernel6      =  3\n",
    "filters7     =  256    #7\n",
    "kernel7      =  3\n",
    "kernel8      =  3      #8\n",
    "stride8      =  2 \n",
    "activation9  =  4096   #9\n",
    "activation10 =  4096   #10\n",
    "outputs11    =  29     #11\n",
    "\n",
    "dropout13=0.5\n",
    "dropout15=0.5\n",
    "learning_rate17=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c789282",
   "metadata": {},
   "source": [
    "That follows the following set of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d7fa9249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation, Activation Shape, Activation Size, #Parameters\n",
      "0 (227, 227, 3)\n",
      "1 ((55, 55, 96), 290400, 34944)\n",
      "2 ((27, 27, 96), 69984, 0)\n",
      "3 ((27, 27, 256), 186624, 614656)\n",
      "4 ((13, 13, 256), 43264, 0)\n",
      "5 ((13, 13, 384), 64896, 885120)\n",
      "6 ((13, 13, 384), 64896, 1327488)\n",
      "7 ((13, 13, 256), 43264, 884992)\n",
      "8 ((6, 6, 256), 9216, 0)\n",
      "9 ((4096, 1), 4096, 37752832)\n",
      "10 ((4096, 1), 4096, 16781312)\n",
      "11 ((1000, 1), 1000, 4097000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Operation,\",\"Activation Shape,\", \"Activation Size,\",\"#Parameters\")\n",
    "for i in range(12):\n",
    "    step=i\n",
    "    layer=parameters[step]\n",
    "    print(step, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a280a",
   "metadata": {},
   "source": [
    "From the standard framework of the **AlexNet** we see that:\n",
    "\n",
    "The  **original** input pictures have the dimensions of \n",
    "\n",
    "**227x227x3**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29523f33",
   "metadata": {},
   "source": [
    "and our pictutes in the **MMORPG-AI** project are:\n",
    "\n",
    "**270x 480x3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e963a7",
   "metadata": {},
   "source": [
    "That means that we have to adapt the template AlexNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9c6eeafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(270, 480, 3)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showarray(X_image[0])\n",
    "X_image[0].shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ddbda2",
   "metadata": {},
   "source": [
    "We should **modify** al the whole neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f668bb",
   "metadata": {},
   "source": [
    "# Modified version of AlexNet - Adapted version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd560c",
   "metadata": {},
   "source": [
    "Let us write the parameters Alexnet network in asimple code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3e44173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    }
   ],
   "source": [
    "parameters={}\n",
    "\n",
    "#Input layer\n",
    "parameters[0]=270,480,3\n",
    "\n",
    "#CONV 1\n",
    "inputs  =parameters[0]  #nw x nh x nc image\n",
    "kernel  = 11,11      #fw x fw  filter\n",
    "stride  = 4.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = 96       #number of filters ncl\n",
    "parameters[1]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "#POOL1\n",
    "inputs  = parameters[1][0] #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "parameters[2]=dim_pool(inputs, kernel,stride,padding)\n",
    "#CONVOLUTION SAME 1\n",
    "inputs  =parameters[2][0] #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 2.0      #padding p\n",
    "filters = 256       #number of filters ncl\n",
    "parameters[3]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[3]) # Checking parameters of same convolution\n",
    "\n",
    "#POOL2\n",
    "inputs  = parameters[3][0] #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "parameters[4]=dim_pool(inputs, kernel,stride,padding)\n",
    "\n",
    "#CONVOLUTION SAME 2\n",
    "inputs  =parameters[4][0] #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = 384       #number of filters ncl\n",
    "parameters[5]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[5]) # Checking parameters of same convolution\n",
    "\n",
    "\n",
    "#CONVOLUTION SAME 3\n",
    "inputs  =parameters[5][0] #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = 384       #number of filters ncl\n",
    "parameters[6]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[6]) # Checking parameters of same convolution\n",
    "\n",
    "\n",
    "#CONVOLUTION SAME 4\n",
    "inputs  =parameters[6][0] #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = 256       #number of filters ncl\n",
    "parameters[7]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[7]) # Checking parameters of same convolution\n",
    "\n",
    "#POOL3\n",
    "inputs  = parameters[7][0] #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "parameters[8]=dim_pool(inputs, kernel,stride,padding)\n",
    "#FC1\n",
    "parameters[9]=nparameters_fully_connected(4096 , parameters[8][1])\n",
    "#FC2\n",
    "parameters[10]=nparameters_fully_connected(parameters[9][1] , parameters[9][1])\n",
    "#Softmax\n",
    "parameters[11]=nparameters_fully_connected(29 , parameters[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68160ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation, Activation Shape, Activation Size, #Parameters\n",
      "0 (270, 480, 3)\n",
      "1 ((65, 118, 96), 736320, 34944)\n",
      "2 ((32, 58, 96), 178176, 0)\n",
      "3 ((32, 58, 256), 475136, 614656)\n",
      "4 ((15, 28, 256), 107520, 0)\n",
      "5 ((15, 28, 384), 161280, 885120)\n",
      "6 ((15, 28, 384), 161280, 1327488)\n",
      "7 ((15, 28, 256), 107520, 884992)\n",
      "8 ((7, 13, 256), 23296, 0)\n",
      "9 ((4096, 1), 4096, 95424512)\n",
      "10 ((4096, 1), 4096, 16781312)\n",
      "11 ((29, 1), 29, 118813)\n"
     ]
    }
   ],
   "source": [
    "print(\"Operation,\",\"Activation Shape,\", \"Activation Size,\",\"#Parameters\")\n",
    "for i in range(12):\n",
    "    step=i\n",
    "    layer=parameters[step]\n",
    "    print(step, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f571827",
   "metadata": {},
   "source": [
    "Meanwhile the orginal AlexNet calculation contains\n",
    "```\n",
    "Operation, Activation Shape, Activation Size, #Parameters\n",
    "0 (227, 227, 3)\n",
    "1 ((55, 55, 96), 290400, 34944)\n",
    "2 ((27, 27, 96), 69984, 0)\n",
    "3 ((27, 27, 256), 186624, 614656)\n",
    "4 ((13, 13, 256), 43264, 0)\n",
    "5 ((13, 13, 384), 64896, 885120)\n",
    "6 ((13, 13, 384), 64896, 1327488)\n",
    "7 ((13, 13, 256), 43264, 884992)\n",
    "8 ((6, 6, 256), 9216, 0)\n",
    "9 ((4096, 1), 4096, 37752832)\n",
    "10 ((4096, 1), 4096, 16781312)\n",
    "11 ((1000, 1), 1000, 4097000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c752d49",
   "metadata": {},
   "source": [
    "The previous results shows how we should modify all the layers in an appropiate way if we want to follow the same structure of the AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee76616",
   "metadata": {},
   "source": [
    "In ordering to improve the Neural Network we can take into account the following best practices:\n",
    "- Is the network size is too small / large?\n",
    "- Check overfitting or underfitting by train history, then chose the best epoch size.\n",
    "- Try initialise weights with different initialization scheme.\n",
    "- Try different activation functions, loss function, optimizer.\n",
    "- **Change layers number and units number**.\n",
    "- Change batch size.\n",
    "- Add dropout layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25a849",
   "metadata": {},
   "source": [
    "Among the best practices mentioned before , we will take into account \"Change layers number and units number.\" Because the original AlexNet were developed taking into account **1000 classes** insted we have only **29 classes** and then does not makes any sense keep the same number of units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87633b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization Parameter\n",
    "Norma        = 29/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8057ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round a float up to next even number\n",
    "import math\n",
    "\n",
    "def roundeven(f):\n",
    "    return math.ceil(f / 2.) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8961b0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roundeven(96*Norma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35739fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roundeven(256*Norma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "833dd002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roundeven(384*Norma) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "946012c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roundeven(4096*Norma) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19bebc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roundeven(1000*Norma) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "972c77ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n",
      "Activation Shape, Activation Size, # Parameters\n"
     ]
    }
   ],
   "source": [
    "parameters={}\n",
    "\n",
    "#Input layer\n",
    "parameters[0]=270,480,3\n",
    "\n",
    "#CONV 1\n",
    "inputs  =parameters[0]  #nw x nh x nc image\n",
    "kernel  = 11,11      #fw x fw  filter\n",
    "stride  = 4.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "filters = roundeven(96*Norma)       #number of filters ncl\n",
    "parameters[1]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "#POOL1\n",
    "inputs  = parameters[1][0] #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "parameters[2]=dim_pool(inputs, kernel,stride,padding)\n",
    "#CONVOLUTION SAME 1\n",
    "inputs  =parameters[2][0] #nw x nh x nc image\n",
    "kernel  = 5,5      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 2.0      #padding p\n",
    "filters = roundeven(256*Norma)      #number of filters ncl\n",
    "parameters[3]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[3]) # Checking parameters of same convolution\n",
    "\n",
    "#POOL2\n",
    "inputs  = parameters[3][0] #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "parameters[4]=dim_pool(inputs, kernel,stride,padding)\n",
    "\n",
    "#CONVOLUTION SAME 2\n",
    "inputs  =parameters[4][0] #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = roundeven(384*Norma)        #number of filters ncl\n",
    "parameters[5]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[5]) # Checking parameters of same convolution\n",
    "\n",
    "\n",
    "#CONVOLUTION SAME 3\n",
    "inputs  =parameters[5][0] #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = roundeven(384*Norma)         #number of filters ncl\n",
    "parameters[6]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[6]) # Checking parameters of same convolution\n",
    "\n",
    "\n",
    "#CONVOLUTION SAME 4\n",
    "inputs  =parameters[6][0] #nw x nh x nc image\n",
    "kernel  = 3,3      #fw x fw  filter\n",
    "stride  = 1.0      #stride s\n",
    "padding = 1.0      #padding p\n",
    "filters = roundeven(256*Norma)       #number of filters ncl\n",
    "parameters[7]=nparameters_convolution(inputs, kernel,stride,padding,filters)\n",
    "check_same(inputs,parameters[7]) # Checking parameters of same convolution\n",
    "\n",
    "#POOL3\n",
    "inputs  = parameters[7][0] #nw x nh x nc \n",
    "kernel  = 3,3     #fw x fw  filter\n",
    "stride  = 2.0      #stride s\n",
    "padding = 0.0      #padding p\n",
    "parameters[8]=dim_pool(inputs, kernel,stride,padding)\n",
    "#FC1\n",
    "parameters[9]=nparameters_fully_connected(roundeven(4096*Norma)  , parameters[8][1])\n",
    "#FC2\n",
    "parameters[10]=nparameters_fully_connected(parameters[9][1] , parameters[9][1])\n",
    "#Softmax\n",
    "parameters[11]=nparameters_fully_connected(int(1000*Norma)  , parameters[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b883bd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation, Activation Shape, Activation Size, #Parameters\n",
      "0 (270, 480, 3)\n",
      "1 ((65, 118, 4), 30680, 1456)\n",
      "2 ((32, 58, 4), 7424, 0)\n",
      "3 ((32, 58, 8), 14848, 808)\n",
      "4 ((15, 28, 8), 3360, 0)\n",
      "5 ((15, 28, 12), 5040, 876)\n",
      "6 ((15, 28, 12), 5040, 1308)\n",
      "7 ((15, 28, 8), 3360, 872)\n",
      "8 ((7, 13, 8), 728, 0)\n",
      "9 ((120, 1), 120, 87480)\n",
      "10 ((120, 1), 120, 14520)\n",
      "11 ((29, 1), 29, 3509)\n"
     ]
    }
   ],
   "source": [
    "print(\"Operation,\",\"Activation Shape,\", \"Activation Size,\",\"#Parameters\")\n",
    "for i in range(12):\n",
    "    step=i\n",
    "    layer=parameters[step]\n",
    "    print(step, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e59db7",
   "metadata": {},
   "source": [
    "First let us define all the parameters of AlexNet adapted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a58aa2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramters                          Operation \n",
    "filters1     =  roundeven(96*Norma)    #1\n",
    "kernel1      =  11       \n",
    "stride1      =  4\n",
    "kernel2      =  3                     #2\n",
    "stride2      =  2\n",
    "filters3     =  roundeven(256*Norma)  #3\n",
    "kernel3      =  5\n",
    "kernel4      =  3                     #4\n",
    "stride4      =  2\n",
    "filters5     =  roundeven(384*Norma)  #5\n",
    "kernel5      =  3\n",
    "filters6     =  roundeven(384*Norma)  #6\n",
    "kernel6      =  3\n",
    "filters7     =  roundeven(256*Norma)  #7\n",
    "kernel7      =  3\n",
    "kernel8      =  3                      #8\n",
    "stride8      =  2 \n",
    "activation9  =  roundeven(4096*Norma)  #9\n",
    "activation10 =  roundeven(4096*Norma)  #10\n",
    "outputs11    =  int(1000*Norma)   #11\n",
    "\n",
    "dropout13=0.5\n",
    "dropout15=0.5\n",
    "learning_rate17=0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d643450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet_adapted(width, height, lr, output=29):\n",
    "    # Building 'AlexNet'                                                               #line\n",
    "    network = input_data(shape=[None, width, height, 3])                               #0\n",
    "    network = conv_2d(network, filters1, kernel1, stride1, activation='relu')          #1\n",
    "    network = max_pool_2d(network, kernel2, strides=stride2 )                          #2\n",
    "    network = local_response_normalization(network)                                    #3\n",
    "    network = conv_2d(network, filters3 , kernel3 , activation='relu')                 #4\n",
    "    network = max_pool_2d(network, kernel4, strides=stride4)                           #5\n",
    "    network = local_response_normalization(network)                                    #6\n",
    "    network = conv_2d(network, filters5 , kernel5 , activation='relu')                 #7\n",
    "    network = conv_2d(network, filters6 , kernel6 , activation='relu')                 #8\n",
    "    network = conv_2d(network, filters7, kernel7 , activation='relu')                  #9\n",
    "    network = max_pool_2d(network, kernel8 , strides=stride8 )                         #10\n",
    "    network = local_response_normalization(network)                                    #11\n",
    "    network = fully_connected(network, activation9, activation='tanh')                 #12\n",
    "    network = dropout(network, dropout13)                                              #13\n",
    "    network = fully_connected(network, activation10, activation='tanh')                #14\n",
    "    network = dropout(network, dropout15)                                              #15\n",
    "    network = fully_connected(network, outputs11, activation='softmax')                #16\n",
    "    network = regression(network, optimizer='momentum',                                #17\n",
    "                         loss='categorical_crossentropy',\n",
    "                         learning_rate=learning_rate17)\n",
    "\n",
    "    # Training\n",
    "    model = tflearn.DNN(network, checkpoint_path='model_alexnet',\n",
    "                        max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir='log')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99c70b",
   "metadata": {},
   "source": [
    "**Learning rate** \n",
    "The learning rate defines how quickly a network updates its parameters.\n",
    "\n",
    "Low learning rate slows down the learning process but converges smoothly. Larger learning rate speeds up the learning but may not converge.\n",
    "\n",
    "Usually a decaying Learning rate is preferred.\n",
    "\n",
    "**Momentum**\n",
    "Momentum helps to know the direction of the next step with the knowledge of the previous steps. It helps to prevent oscillations. A typical choice of momentum is between 0.5 to 0.9.\n",
    "\n",
    "**Number of epochs**\n",
    "Number of epochs is the number of times the whole training data is shown to the network while training.\n",
    "\n",
    "Increase the number of epochs until the validation accuracy starts decreasing even when training accuracy is increasing(overfitting).\n",
    "\n",
    "**Batch size**\n",
    "Mini batch size is the number of sub samples given to the network after which parameter update happens.\n",
    "\n",
    "\n",
    "The activation function is a node that is put at the end of or in between Neural Networks. The activation function is the non linear transformation that we do over the input signal. This transformed output is then sent to the next layer of neurons as input.\n",
    "\n",
    "A good default for batch size might be 32. Also try 32, 64, 128, 256, and so o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c23570d",
   "metadata": {},
   "source": [
    "The adapted version of the AlexNet model does not modify the latest size of the neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e066ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mmorpg-0.001-alex-adaptedd.model'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = 1e-3\n",
    "MODEL_NAME = 'mmorpg-{}-{}.model'.format(LR, 'alex-adaptedd') \n",
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f756e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet_adapted(WIDTH, HEIGHT, LR, output=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39569c",
   "metadata": {},
   "source": [
    "We train the modifed  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dcf7fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m5.73289\u001b[0m\u001b[0m | time: 0.314s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 005 | loss: 5.73289 - acc: 0.7145 -- iter: 180/180\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=5, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=64, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2b3e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m4.97291\u001b[0m\u001b[0m | time: 0.406s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 010 | loss: 4.97291 - acc: 0.7783 -- iter: 180/180\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=5, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=256, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e87cac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m3.99376\u001b[0m\u001b[0m | time: 0.332s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 015 | loss: 3.99376 - acc: 0.8277 -- iter: 180/180\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=5, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=512, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28651741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m3.01139\u001b[0m\u001b[0m | time: 0.293s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 020 | loss: 3.01139 - acc: 0.8259 -- iter: 180/180\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=5, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=1024, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34c1da38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m2.26618\u001b[0m\u001b[0m | time: 0.277s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 025 | loss: 2.26618 - acc: 0.7786 -- iter: 180/180\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=5, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=1024*2, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d09a618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m1.85039\u001b[0m\u001b[0m | time: 1.440s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 030 | loss: 1.85039 - acc: 0.6351 -- iter: 180/180\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=5, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=1024*3, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68a1a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m1.42784\u001b[0m\u001b[0m | time: 0.364s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 060 | loss: 1.42784 - acc: 0.5493 -- iter: 180/180\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=15, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=1024*3, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d221c90",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f77452",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/38968249/cannot-run-tflearn-with-sklearns-gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48284688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4bc653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import tflearn\n",
    "import tflearn.datasets.mnist as mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6cef340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MNIST...\n",
      "Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Downloading MNIST...\n",
      "Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading MNIST...\n",
      "Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading MNIST...\n",
      "Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      ":0.89\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = mnist.load_data(one_hot=False)\n",
    "#Build the model, select the kernel function and train\n",
    "clf = SVC()\n",
    "clf.set_params(kernel='rbf', probability=True).fit(x_train[:1000,:], y_train[:1000])\n",
    "preds1 = clf.predict(x_test[:1000,:])\n",
    "print(\":\"+str(np.mean(preds1 == y_test[:1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abf69001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the parameters to be transformed\n",
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fe5d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build an automatic parameter tuning container, the n_jobs parameter supports multiple processes running parallel tests at the same time\n",
    "grid_search = GridSearchCV(clf, param_grid, n_jobs = 1, verbose=10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57ed45f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5; 1/16] START C=0.0001, gamma=0.001......................................\n",
      "[CV 1/5; 1/16] END .......C=0.0001, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 2/5; 1/16] START C=0.0001, gamma=0.001......................................\n",
      "[CV 2/5; 1/16] END .......C=0.0001, gamma=0.001;, score=0.115 total time=   1.0s\n",
      "[CV 3/5; 1/16] START C=0.0001, gamma=0.001......................................\n",
      "[CV 3/5; 1/16] END .......C=0.0001, gamma=0.001;, score=0.115 total time=   1.0s\n",
      "[CV 4/5; 1/16] START C=0.0001, gamma=0.001......................................\n",
      "[CV 4/5; 1/16] END .......C=0.0001, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 5/5; 1/16] START C=0.0001, gamma=0.001......................................\n",
      "[CV 5/5; 1/16] END .......C=0.0001, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 1/5; 2/16] START C=0.0001, gamma=0.0001.....................................\n",
      "[CV 1/5; 2/16] END ......C=0.0001, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 2/5; 2/16] START C=0.0001, gamma=0.0001.....................................\n",
      "[CV 2/5; 2/16] END ......C=0.0001, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 3/5; 2/16] START C=0.0001, gamma=0.0001.....................................\n",
      "[CV 3/5; 2/16] END ......C=0.0001, gamma=0.0001;, score=0.115 total time=   1.2s\n",
      "[CV 4/5; 2/16] START C=0.0001, gamma=0.0001.....................................\n",
      "[CV 4/5; 2/16] END ......C=0.0001, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 5/5; 2/16] START C=0.0001, gamma=0.0001.....................................\n",
      "[CV 5/5; 2/16] END ......C=0.0001, gamma=0.0001;, score=0.115 total time=   1.2s\n",
      "[CV 1/5; 3/16] START C=0.001, gamma=0.001.......................................\n",
      "[CV 1/5; 3/16] END ........C=0.001, gamma=0.001;, score=0.115 total time=   1.0s\n",
      "[CV 2/5; 3/16] START C=0.001, gamma=0.001.......................................\n",
      "[CV 2/5; 3/16] END ........C=0.001, gamma=0.001;, score=0.115 total time=   1.2s\n",
      "[CV 3/5; 3/16] START C=0.001, gamma=0.001.......................................\n",
      "[CV 3/5; 3/16] END ........C=0.001, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 4/5; 3/16] START C=0.001, gamma=0.001.......................................\n",
      "[CV 4/5; 3/16] END ........C=0.001, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 5/5; 3/16] START C=0.001, gamma=0.001.......................................\n",
      "[CV 5/5; 3/16] END ........C=0.001, gamma=0.001;, score=0.115 total time=   1.2s\n",
      "[CV 1/5; 4/16] START C=0.001, gamma=0.0001......................................\n",
      "[CV 1/5; 4/16] END .......C=0.001, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 2/5; 4/16] START C=0.001, gamma=0.0001......................................\n",
      "[CV 2/5; 4/16] END .......C=0.001, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 3/5; 4/16] START C=0.001, gamma=0.0001......................................\n",
      "[CV 3/5; 4/16] END .......C=0.001, gamma=0.0001;, score=0.115 total time=   1.2s\n",
      "[CV 4/5; 4/16] START C=0.001, gamma=0.0001......................................\n",
      "[CV 4/5; 4/16] END .......C=0.001, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 5/5; 4/16] START C=0.001, gamma=0.0001......................................\n",
      "[CV 5/5; 4/16] END .......C=0.001, gamma=0.0001;, score=0.115 total time=   1.2s\n",
      "[CV 1/5; 5/16] START C=0.01, gamma=0.001........................................\n",
      "[CV 1/5; 5/16] END .........C=0.01, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 2/5; 5/16] START C=0.01, gamma=0.001........................................\n",
      "[CV 2/5; 5/16] END .........C=0.01, gamma=0.001;, score=0.115 total time=   1.2s\n",
      "[CV 3/5; 5/16] START C=0.01, gamma=0.001........................................\n",
      "[CV 3/5; 5/16] END .........C=0.01, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 4/5; 5/16] START C=0.01, gamma=0.001........................................\n",
      "[CV 4/5; 5/16] END .........C=0.01, gamma=0.001;, score=0.115 total time=   1.2s\n",
      "[CV 5/5; 5/16] START C=0.01, gamma=0.001........................................\n",
      "[CV 5/5; 5/16] END .........C=0.01, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 1/5; 6/16] START C=0.01, gamma=0.0001.......................................\n",
      "[CV 1/5; 6/16] END ........C=0.01, gamma=0.0001;, score=0.115 total time=   1.2s\n",
      "[CV 2/5; 6/16] START C=0.01, gamma=0.0001.......................................\n",
      "[CV 2/5; 6/16] END ........C=0.01, gamma=0.0001;, score=0.115 total time=   1.2s\n",
      "[CV 3/5; 6/16] START C=0.01, gamma=0.0001.......................................\n",
      "[CV 3/5; 6/16] END ........C=0.01, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 4/5; 6/16] START C=0.01, gamma=0.0001.......................................\n",
      "[CV 4/5; 6/16] END ........C=0.01, gamma=0.0001;, score=0.115 total time=   1.2s\n",
      "[CV 5/5; 6/16] START C=0.01, gamma=0.0001.......................................\n",
      "[CV 5/5; 6/16] END ........C=0.01, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 1/5; 7/16] START C=0.1, gamma=0.001.........................................\n",
      "[CV 1/5; 7/16] END ..........C=0.1, gamma=0.001;, score=0.115 total time=   1.2s\n",
      "[CV 2/5; 7/16] START C=0.1, gamma=0.001.........................................\n",
      "[CV 2/5; 7/16] END ..........C=0.1, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 3/5; 7/16] START C=0.1, gamma=0.001.........................................\n",
      "[CV 3/5; 7/16] END ..........C=0.1, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 4/5; 7/16] START C=0.1, gamma=0.001.........................................\n",
      "[CV 4/5; 7/16] END ..........C=0.1, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 5/5; 7/16] START C=0.1, gamma=0.001.........................................\n",
      "[CV 5/5; 7/16] END ..........C=0.1, gamma=0.001;, score=0.115 total time=   1.1s\n",
      "[CV 1/5; 8/16] START C=0.1, gamma=0.0001........................................\n",
      "[CV 1/5; 8/16] END .........C=0.1, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 2/5; 8/16] START C=0.1, gamma=0.0001........................................\n",
      "[CV 2/5; 8/16] END .........C=0.1, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 3/5; 8/16] START C=0.1, gamma=0.0001........................................\n",
      "[CV 3/5; 8/16] END .........C=0.1, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 4/5; 8/16] START C=0.1, gamma=0.0001........................................\n",
      "[CV 4/5; 8/16] END .........C=0.1, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 5/5; 8/16] START C=0.1, gamma=0.0001........................................\n",
      "[CV 5/5; 8/16] END .........C=0.1, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 1/5; 9/16] START C=1, gamma=0.001...........................................\n",
      "[CV 1/5; 9/16] END ............C=1, gamma=0.001;, score=0.795 total time=   0.8s\n",
      "[CV 2/5; 9/16] START C=1, gamma=0.001...........................................\n",
      "[CV 2/5; 9/16] END ............C=1, gamma=0.001;, score=0.795 total time=   0.8s\n",
      "[CV 3/5; 9/16] START C=1, gamma=0.001...........................................\n",
      "[CV 3/5; 9/16] END ............C=1, gamma=0.001;, score=0.830 total time=   0.9s\n",
      "[CV 4/5; 9/16] START C=1, gamma=0.001...........................................\n",
      "[CV 4/5; 9/16] END ............C=1, gamma=0.001;, score=0.815 total time=   0.8s\n",
      "[CV 5/5; 9/16] START C=1, gamma=0.001...........................................\n",
      "[CV 5/5; 9/16] END ............C=1, gamma=0.001;, score=0.850 total time=   0.8s\n",
      "[CV 1/5; 10/16] START C=1, gamma=0.0001.........................................\n",
      "[CV 1/5; 10/16] END ..........C=1, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 2/5; 10/16] START C=1, gamma=0.0001.........................................\n",
      "[CV 2/5; 10/16] END ..........C=1, gamma=0.0001;, score=0.120 total time=   1.1s\n",
      "[CV 3/5; 10/16] START C=1, gamma=0.0001.........................................\n",
      "[CV 3/5; 10/16] END ..........C=1, gamma=0.0001;, score=0.125 total time=   1.1s\n",
      "[CV 4/5; 10/16] START C=1, gamma=0.0001.........................................\n",
      "[CV 4/5; 10/16] END ..........C=1, gamma=0.0001;, score=0.115 total time=   1.2s\n",
      "[CV 5/5; 10/16] START C=1, gamma=0.0001.........................................\n",
      "[CV 5/5; 10/16] END ..........C=1, gamma=0.0001;, score=0.115 total time=   1.1s\n",
      "[CV 1/5; 11/16] START C=10, gamma=0.001.........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/16] END ..........C=10, gamma=0.001;, score=0.860 total time=   0.4s\n",
      "[CV 2/5; 11/16] START C=10, gamma=0.001.........................................\n",
      "[CV 2/5; 11/16] END ..........C=10, gamma=0.001;, score=0.880 total time=   0.4s\n",
      "[CV 3/5; 11/16] START C=10, gamma=0.001.........................................\n",
      "[CV 3/5; 11/16] END ..........C=10, gamma=0.001;, score=0.910 total time=   0.4s\n",
      "[CV 4/5; 11/16] START C=10, gamma=0.001.........................................\n",
      "[CV 4/5; 11/16] END ..........C=10, gamma=0.001;, score=0.890 total time=   0.4s\n",
      "[CV 5/5; 11/16] START C=10, gamma=0.001.........................................\n",
      "[CV 5/5; 11/16] END ..........C=10, gamma=0.001;, score=0.910 total time=   0.4s\n",
      "[CV 1/5; 12/16] START C=10, gamma=0.0001........................................\n",
      "[CV 1/5; 12/16] END .........C=10, gamma=0.0001;, score=0.795 total time=   0.8s\n",
      "[CV 2/5; 12/16] START C=10, gamma=0.0001........................................\n",
      "[CV 2/5; 12/16] END .........C=10, gamma=0.0001;, score=0.805 total time=   0.8s\n",
      "[CV 3/5; 12/16] START C=10, gamma=0.0001........................................\n",
      "[CV 3/5; 12/16] END .........C=10, gamma=0.0001;, score=0.835 total time=   0.8s\n",
      "[CV 4/5; 12/16] START C=10, gamma=0.0001........................................\n",
      "[CV 4/5; 12/16] END .........C=10, gamma=0.0001;, score=0.820 total time=   0.8s\n",
      "[CV 5/5; 12/16] START C=10, gamma=0.0001........................................\n",
      "[CV 5/5; 12/16] END .........C=10, gamma=0.0001;, score=0.850 total time=   0.9s\n",
      "[CV 1/5; 13/16] START C=100, gamma=0.001........................................\n",
      "[CV 1/5; 13/16] END .........C=100, gamma=0.001;, score=0.855 total time=   0.4s\n",
      "[CV 2/5; 13/16] START C=100, gamma=0.001........................................\n",
      "[CV 2/5; 13/16] END .........C=100, gamma=0.001;, score=0.905 total time=   0.4s\n",
      "[CV 3/5; 13/16] START C=100, gamma=0.001........................................\n",
      "[CV 3/5; 13/16] END .........C=100, gamma=0.001;, score=0.925 total time=   0.4s\n",
      "[CV 4/5; 13/16] START C=100, gamma=0.001........................................\n",
      "[CV 4/5; 13/16] END .........C=100, gamma=0.001;, score=0.880 total time=   0.3s\n",
      "[CV 5/5; 13/16] START C=100, gamma=0.001........................................\n",
      "[CV 5/5; 13/16] END .........C=100, gamma=0.001;, score=0.915 total time=   0.3s\n",
      "[CV 1/5; 14/16] START C=100, gamma=0.0001.......................................\n",
      "[CV 1/5; 14/16] END ........C=100, gamma=0.0001;, score=0.855 total time=   0.4s\n",
      "[CV 2/5; 14/16] START C=100, gamma=0.0001.......................................\n",
      "[CV 2/5; 14/16] END ........C=100, gamma=0.0001;, score=0.880 total time=   0.4s\n",
      "[CV 3/5; 14/16] START C=100, gamma=0.0001.......................................\n",
      "[CV 3/5; 14/16] END ........C=100, gamma=0.0001;, score=0.910 total time=   0.4s\n",
      "[CV 4/5; 14/16] START C=100, gamma=0.0001.......................................\n",
      "[CV 4/5; 14/16] END ........C=100, gamma=0.0001;, score=0.885 total time=   0.4s\n",
      "[CV 5/5; 14/16] START C=100, gamma=0.0001.......................................\n",
      "[CV 5/5; 14/16] END ........C=100, gamma=0.0001;, score=0.905 total time=   0.4s\n",
      "[CV 1/5; 15/16] START C=1000, gamma=0.001.......................................\n",
      "[CV 1/5; 15/16] END ........C=1000, gamma=0.001;, score=0.850 total time=   0.3s\n",
      "[CV 2/5; 15/16] START C=1000, gamma=0.001.......................................\n",
      "[CV 2/5; 15/16] END ........C=1000, gamma=0.001;, score=0.905 total time=   0.3s\n",
      "[CV 3/5; 15/16] START C=1000, gamma=0.001.......................................\n",
      "[CV 3/5; 15/16] END ........C=1000, gamma=0.001;, score=0.925 total time=   0.3s\n",
      "[CV 4/5; 15/16] START C=1000, gamma=0.001.......................................\n",
      "[CV 4/5; 15/16] END ........C=1000, gamma=0.001;, score=0.880 total time=   0.3s\n",
      "[CV 5/5; 15/16] START C=1000, gamma=0.001.......................................\n",
      "[CV 5/5; 15/16] END ........C=1000, gamma=0.001;, score=0.920 total time=   0.3s\n",
      "[CV 1/5; 16/16] START C=1000, gamma=0.0001......................................\n",
      "[CV 1/5; 16/16] END .......C=1000, gamma=0.0001;, score=0.840 total time=   0.4s\n",
      "[CV 2/5; 16/16] START C=1000, gamma=0.0001......................................\n",
      "[CV 2/5; 16/16] END .......C=1000, gamma=0.0001;, score=0.905 total time=   0.4s\n",
      "[CV 3/5; 16/16] START C=1000, gamma=0.0001......................................\n",
      "[CV 3/5; 16/16] END .......C=1000, gamma=0.0001;, score=0.925 total time=   0.4s\n",
      "[CV 4/5; 16/16] START C=1000, gamma=0.0001......................................\n",
      "[CV 4/5; 16/16] END .......C=1000, gamma=0.0001;, score=0.860 total time=   0.3s\n",
      "[CV 5/5; 16/16] START C=1000, gamma=0.0001......................................\n",
      "[CV 5/5; 16/16] END .......C=1000, gamma=0.0001;, score=0.910 total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(probability=True), n_jobs=1,\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [0.001, 0.0001]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train[:1000,:], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b689a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 100\n",
      "break_ties False\n",
      "cache_size 200\n",
      "class_weight None\n",
      "coef0 0.0\n",
      "decision_function_shape ovr\n",
      "degree 3\n",
      "gamma 0.001\n",
      "kernel rbf\n",
      "max_iter -1\n",
      "probability True\n",
      "random_state None\n",
      "shrinking True\n",
      "tol 0.001\n",
      "verbose False\n",
      "0.878\n"
     ]
    }
   ],
   "source": [
    "#Select the best parameters\n",
    "best_parameters = grid_search.best_estimator_.get_params()    \n",
    "for para, val in list(best_parameters.items()):    \n",
    "    print(para, val)\n",
    "#train with optimal parameters\n",
    "clf = SVC(kernel='rbf', C=best_parameters['C'], gamma=best_parameters['gamma'], probability=True).fit(x_train[:1000,:], y_train[:1000])\n",
    "preds1 = clf.predict(x_test[:1000,:])\n",
    "print(\"Optimal test set validation score\"+str(np.mean(preds1 == y_test[:1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90b44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283461b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc83a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631efe0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pygta5)",
   "language": "python",
   "name": "pygta5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
